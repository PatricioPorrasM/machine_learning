---
title: "MidTerm Clasificaci贸n"
author: "Patricio Porras"
---

## Introducci贸n

Este documento presenta un an谩lisis completo de regresi贸n lineal utilizando el dataset `AcademicStressLevel.csv`. Utilizaremos Pipeline de scikit-learn para crear un flujo de trabajo robusto y reproducible.

***

## 1. Importar Librer铆as

Primero importamos todas las librer铆as necesarias para el an谩lisis.

```{python}
# Librer铆as para manipulaci贸n de datos
import pandas as pd
import numpy as np

# Librer铆as para visualizaci贸n
import matplotlib.pyplot as plt
import seaborn as sns

# Librer铆as de scikit-learn
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Configuraci贸n de estilo para gr谩ficos
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
```

## 2. Carga el Dataset

Primero, cargamos las librer铆as necesarias y el conjunto de datos. Realizaremos una exploraci贸n b谩sica para entender su estructura, identificar las variables num茅ricas y categ贸ricas, y prepararlo para el modelo.

```{python}

# Cargar el dataset desde el archivo CSV
file_path = 'AcademicStressLevel.csv'
df = pd.read_csv(file_path)
```

## 3. Exploraci贸n Inicial del Dataset

### 3.1 Exploraci贸n inicial

```{python}
# --- Exploraci贸n Inicial ---
print("--- Informaci贸n General del Dataset ---")
df.info()

print("\n--- Primeras 5 Filas del Dataset ---")
print(df.head())

```

### 3.2 renombrado de clumnas
Se renombra kas columnas para mejor facilidad de manipularlas

```{python}
# --- Limpieza y Selecci贸n de Caracter铆sticas ---
# Limpiar nombres de columnas antes de renombrar
df.columns = df.columns.str.strip()

# Los nombres de las columnas son largos y contienen espacios. Vamos a renombrarlos.
column_mapping = {
    'Your Academic Stage': 'academic_stage',
    'Peer pressure': 'peer_pressure',
    'Academic pressure from your home': 'home_pressure',
    'Study Environment': 'study_environment',
    'What coping strategy you use as a student?': 'coping_strategy',
    'Do you have any bad habits like smoking, drinking on a daily basis?': 'bad_habits',
    'What would you rate the academic  competition in your student life': 'competition_rating',
    'Rate your academic stress index': 'stress_index'
}
df = df.rename(columns=column_mapping)

```

Ver columnas renombradas

```{python}
print("--- Informaci贸n General del Dataset renombado ---")
df.info()

```

### 3.3 Evitar el us de variables categ贸ricas
```{python}

# Seg煤n los lineamientos, debemos evitar el uso de variables categ贸ricas.
# Identificamos las columnas categ贸ricas a eliminar:
categorical_cols = ['academic_stage', 'study_environment', 'coping_strategy', 'bad_habits']
# Tambi茅n eliminamos 'Timestamp' por no ser relevante para el modelo.
cols_to_drop = categorical_cols + ['Timestamp']

df_cleaned = df.drop(columns=cols_to_drop)

# Verificamos si hay valores nulos
print(f"\n--- Valores Nulos por Columna (despu茅s de limpiar) ---")
print(df_cleaned.isnull().sum())

# Si hubiera valores nulos, una opci贸n ser铆a eliminarlos.
# df_cleaned = df_cleaned.dropna()

print("\n--- Dataset Limpio (solo variables num茅ricas) ---")
print(df_cleaned.head())

print("\n--- Descripci贸n Estad铆stica del Dataset Limpio ---")
print(df_cleaned.describe())
```

**Interpretaci贸n de la Exploraci贸n:**
El dataset original contiene una mezcla de variables num茅ricas y categ贸ricas. Para cumplir con los requisitos, hemos eliminado las columnas categ贸ricas (`academic_stage`, `study_environment`, etc.) y la columna `Timestamp`. Nos quedamos con las siguientes variables num茅ricas: `peer_pressure`, `home_pressure`, `competition_rating` como nuestras **caracter铆sticas (features)**, y `stress_index` como nuestra **variable objetivo (target)**. Afortunadamente, no se encontraron valores nulos en las columnas seleccionadas.


## 4\. Divisi贸n en Conjuntos de Entrenamiento y Prueba

Ahora, dividimos nuestro dataset limpio en dos conjuntos: uno para **entrenar** el modelo y otro para **evaluarlo** de manera imparcial. Usaremos una divisi贸n 80/20, que es un est谩ndar com煤n en la industria.

```{python}
#| label: division-datos
#| echo: true

# Definir las caracter铆sticas (X) y la variable objetivo (y)
X = df_cleaned.drop('stress_index', axis=1)
y = df_cleaned['stress_index']

# Dividir los datos en entrenamiento (80%) y prueba (20%)
# Usamos random_state para que la divisi贸n sea reproducible
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("--- Dimensiones de los Conjuntos de Datos ---")
print(f"Forma de X_train: {X_train.shape}")
print(f"Forma de X_test: {X_test.shape}")
print(f"Forma de y_train: {y_train.shape}")
print(f"Forma de y_test: {y_test.shape}")
```

**Nota:** Se utiliz贸 el par谩metro `stratify=y` para asegurar que la proporci贸n de cada clase de estr茅s sea la misma tanto en el conjunto de entrenamiento como en el de prueba. Esto es crucial en problemas de clasificaci贸n, especialmente si las clases est谩n desbalanceadas.

-----

## 5\. Definici贸n y Entrenamiento del Modelo utilizando Pipeline

Aqu铆 creamos el `Pipeline`. Este objeto encapsula una secuencia de transformaciones y un estimador final. Nuestro pipeline constar谩 de dos pasos:

1.  **`StandardScaler`**: Estandariza las caracter铆sticas eliminando la media y escalando a la varianza unitaria. Es un paso fundamental para modelos como la Regresi贸n Log铆stica.
2.  **`LogisticRegression`**: El modelo de clasificaci贸n que queremos entrenar.

El `Pipeline` se entrena con una sola llamada al m茅todo `.fit()`.

```{python}
#| label: pipeline-entrenamiento
#| echo: true

# Definir los pasos del pipeline
# Paso 1: Escalar los datos
# Paso 2: Aplicar el modelo de Regresi贸n Log铆stica
pipeline_steps = [
    ('scaler', StandardScaler()),
    ('logreg', LogisticRegression(random_state=42, multi_class='auto', solver='lbfgs'))
]

# Crear el pipeline
model_pipeline = Pipeline(pipeline_steps)

# Entrenar el pipeline completo con los datos de entrenamiento
print("--- Entrenando el Pipeline ---")
model_pipeline.fit(X_train, y_train)
print("隆Entrenamiento completado!")
```

-----

## 6\. Generaci贸n de Predicciones

Una vez que el pipeline est谩 entrenado, lo usamos para hacer predicciones sobre el conjunto de prueba (`X_test`). El pipeline se encarga autom谩ticamente de aplicar la misma transformaci贸n de escalado que aprendi贸 de los datos de entrenamiento antes de pasar los datos al modelo para la predicci贸n.

```{python}
#| label: predicciones
#| echo: true

# Realizar predicciones sobre el conjunto de prueba
y_pred = model_pipeline.predict(X_test)

# Mostrar algunas predicciones junto con los valores reales
predictions_df = pd.DataFrame({'Valor Real': y_test, 'Predicci贸n': y_pred})
print("--- Muestra de Predicciones vs. Valores Reales ---")
print(predictions_df.head(10))
```

-----

## 7\. Evaluaci贸n del Modelo

Para medir qu茅 tan bien funcion贸 nuestro modelo, utilizamos m茅tricas de clasificaci贸n clave:

  * **Accuracy (Exactitud)**: El porcentaje de predicciones correctas.
  * **Classification Report**: Un resumen que incluye:
      * **Precision**: De todas las veces que el modelo predijo una clase, 驴qu茅 porcentaje fue correcto?
      * **Recall (Sensibilidad)**: De todos los ejemplos reales de una clase, 驴qu茅 porcentaje identific贸 correctamente el modelo?
      * **F1-Score**: La media arm贸nica de precisi贸n y recall, 煤til para clases desbalanceadas.
  * **Matriz de Confusi贸n**: Una tabla que visualiza el rendimiento, mostrando los verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.

<!-- end list -->

```{python}
#| label: evaluacion
#| echo: true

# Calcular la exactitud del modelo
accuracy = accuracy_score(y_test, y_pred)
print(f"--- Exactitud (Accuracy) del Modelo ---")
print(f"Accuracy: {accuracy:.4f}")

# Generar el reporte de clasificaci贸n
print("\n--- Reporte de Clasificaci贸n ---")
print(classification_report(y_test, y_pred))

# Generar la matriz de confusi贸n
print("\n--- Matriz de Confusi贸n ---")
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)
```

-----

## 8\. Visualizaciones e Interpretaci贸n de Resultados

Una visualizaci贸n de la matriz de confusi贸n facilita enormemente su interpretaci贸n. Usaremos un mapa de calor (`heatmap`) de Seaborn.

```{python}
#| label: visualizacion
#| echo: true
#| fig-cap: "Matriz de Confusi贸n del Modelo de Regresi贸n Log铆stica"

# Visualizar la matriz de confusi贸n con un mapa de calor
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
            xticklabels=np.unique(y), yticklabels=np.unique(y))
plt.xlabel('Etiqueta Predicha')
plt.ylabel('Etiqueta Real')
plt.title('Matriz de Confusi贸n')
plt.show()
```

### **Interpretaci贸n Final** 

1.  **Rendimiento General**: La **exactitud (accuracy)** nos da una idea general del porcentaje de predicciones correctas. Sin embargo, en problemas con m煤ltiples clases, no cuenta toda la historia.
2.  **Reporte de Clasificaci贸n**: Analizando el reporte, podemos ver el rendimiento del modelo para cada nivel de estr茅s. Por ejemplo, podr铆amos notar que el modelo tiene alta precisi贸n y recall para las clases con m谩s muestras (ej. estr茅s nivel 3 o 4), pero un rendimiento m谩s bajo para clases menos frecuentes.
3.  **Matriz de Confusi贸n**: El gr谩fico nos permite ver exactamente d贸nde se equivoca el modelo. La diagonal principal (de arriba a la izquierda a abajo a la derecha) muestra las predicciones correctas. Los n煤meros fuera de la diagonal son los errores. Por ejemplo, un n煤mero alto en la fila "Real 4" y la columna "Predicha 3" indicar铆a que el modelo tiende a confundir un nivel de estr茅s real de 4 con uno de 3.

En resumen, el modelo de Regresi贸n Log铆stica implementado a trav茅s de un pipeline nos ofrece una base s贸lida para predecir el estr茅s acad茅mico. Para mejorar los resultados, los siguientes pasos podr铆an incluir la ingenier铆a de caracter铆sticas o probar modelos m谩s complejos, siempre manteniendo una estructura de trabajo ordenada como la que hemos definido aqu铆.
