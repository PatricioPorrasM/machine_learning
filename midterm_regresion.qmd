---
title: "MidTerm Regresi√≥n"
author: "Patricio Porras"
---

## Introducci√≥n

Este documento presenta un an√°lisis completo de regresi√≥n lineal utilizando el dataset `iige003_carapungo.csv`. Utilizaremos Pipeline de scikit-learn para crear un flujo de trabajo robusto y reproducible.

### Columnas

* No: N√∫mero secuencial de la observaci√≥n.
* Date: Fecha de ka observaci√≥n.
* Time: Hora de la observaci√≥n.
* ColdJunc0: Temperatura de la uni√≥n fr√≠a (referencia para sensores tipo termopar). 
* PowerVolt: Voltaje de alimentaci√≥n del sistema o sensor. 
* PowerKind: Tipo de fuente de energ√≠a (por ejemplo, solar, bater√≠a, red el√©ctrica). 
* WS(ave): Velocidad promedio del viento (Wind Speed average), usualmente en m/s. 
* WD(ave): Direcci√≥n promedio del viento (Wind Direction average), en grados. 
* Max_time: Tiempo (hora/minuto) en el que se registr√≥ la velocidad m√°xima del viento (WS(max)) durante el periodo de medici√≥n. 
* WS(max): Velocidad m√°xima del viento registrada en el periodo, en m/s. 
* WD(most): Direcci√≥n del viento m√°s frecuente (Wind Direction most), es decir, la direcci√≥n en la que el viento sopl√≥ la mayor parte del tiempo durante el periodo de medici√≥n. 
* WS(inst_m): Velocidad instant√°nea m√°xima del viento (Wind Speed instantaneous max), en m/s. 
* WD(inst_m): Direcci√≥n instant√°nea m√°xima del viento, en grados. 
* Solar_rad: Radiaci√≥n solar, normalmente en W/m¬≤. 
* TEMP: Temperatura del aire, en ¬∞C. 
* Humidity: Humedad relativa del aire, en %. 
* Rainfall: Precipitaci√≥n acumulada, en mm. 
* Bar_press.: Presi√≥n barom√©trica (atmosf√©rica), en hPa o mbar. 

***

## 1. Importar Librer√≠as

Primero importamos todas las librer√≠as necesarias para el an√°lisis.

```{python}
# Librer√≠as para manipulaci√≥n de datos
import pandas as pd
import numpy as np

# Librer√≠as para visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns

# Librer√≠as de scikit-learn
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Configuraci√≥n de estilo para gr√°ficos
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
```

## 2. Cargar el Dataset

Cargamos el dataset desde el archivo CSV.

```{python}
# Cargar los datos
df = pd.read_csv("iige003_carapungo.csv", encoding="latin1")

# Mostrar informaci√≥n b√°sica
print(f"Dimensiones del dataset: {df.shape}")
print(f"N√∫mero de filas: {df.shape[0]}")
print(f"N√∫mero de columnas: {df.shape[1]}")
```


## 3. Exploraci√≥n Inicial de los Datos

### 3.1 Primeras filas del dataset

```{python}
# Visualizar las primeras 5 filas
df.head()
```

### 3.2 Informaci√≥n del dataset

```{python}
# Informaci√≥n general del dataset
df.info()
```

### 3.3 Transaformar columnas

```{python}
cols_to_numeric = df.columns[3:]
df[cols_to_numeric] = df[cols_to_numeric].apply(pd.to_numeric, errors='coerce')
```


### 3.4 Eliminar columnas que no aportan
Se elimina las columnas que no aportanin fromaci√≥n.

```{python}
# Eliminar las tres primeras columnas
df = df.iloc[:, 3:]

# Eliminar columnas espec√≠ficas por nombre
df = df.drop(columns=["WD(most)", "Max_time"], errors="ignore")

```


```{python}
df.info()
```

### 3.5 Estad√≠sticas descriptivas

```{python}
df.describe()
```

### 3.6 Asignar valores medios a los nulos

```{python}
# Reemplazar valores NaN en columnas num√©ricas por la media de cada columna
df = df.fillna(df.mean(numeric_only=True))
```

### 3.6 Valores nulos

```{python}
# Verificar valores nulos por columna
valores_nulos = df.isnull().sum()
print("Valores nulos por columna:")
print(valores_nulos)
print(f"\nTotal de valores nulos: {valores_nulos.sum()}")
```




## 4. An√°lisis Exploratorio de Datos (EDA)

### 4.1 Distribuci√≥n de las variables

Visualizamos la distribuci√≥n de todas las variables num√©ricas mediante histogramas.

```{python}
#| fig-width: 12
#| fig-height: 8
#| label: fig-histogramas
#| fig-cap: "Distribuci√≥n de las variables num√©ricas del dataset"

# Crear histogramas para todas las variables num√©ricas
df.hist(figsize=(12, 8), bins=20, edgecolor='black')
plt.tight_layout()
plt.show()
```

### 4.2 Matriz de correlaci√≥n

La matriz de correlaci√≥n nos ayuda a identificar relaciones lineales entre variables.

```{python}
#| fig-width: 10
#| fig-height: 8
#| label: fig-correlacion
#| fig-cap: "Matriz de correlaci√≥n entre variables"

# Crear matriz de correlaci√≥n
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f', 
            square=True, linewidths=0.5, cbar_kws={"shrink": 0.8})
plt.title('Matriz de Correlaci√≥n', fontsize=16, pad=20)
plt.tight_layout()
plt.show()
```

### 4.3 An√°lisis de correlaciones fuertes

```{python}
# Encontrar correlaciones fuertes (>0.7 o <-0.7)
corr_matrix = df.corr()
correlaciones_fuertes = []

for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > 0.7:
            correlaciones_fuertes.append({
                'Variable 1': corr_matrix.columns[i],
                'Variable 2': corr_matrix.columns[j],
                'Correlaci√≥n': corr_matrix.iloc[i, j]
            })

if correlaciones_fuertes:
    print("Correlaciones fuertes encontradas (|r| > 0.7):")
    print(pd.DataFrame(correlaciones_fuertes))
else:
    print("No se encontraron correlaciones fuertes (|r| > 0.7)")
```

## 5. Preparaci√≥n de los Datos

Separamos las variables independientes (features) de la variable objetivo.

```{python}
variable_objetivo = 'Rainfall'  

# Separar features (X) y target (y)
X = df.drop(variable_objetivo, axis=1)
y = df[variable_objetivo]

print(f"N√∫mero de features: {X.shape[1]}")
print(f"Features utilizadas: {list(X.columns)}")
```

## 6. Divisi√≥n de Datos

Dividimos el dataset en conjuntos de entrenamiento (80%) y prueba (20%).

```{python}
# Dividir los datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Tama√±o del conjunto de entrenamiento: {X_train.shape[0]} muestras")
print(f"Tama√±o del conjunto de prueba: {X_test.shape[0]} muestras")
print(f"Proporci√≥n: {X_train.shape[0]/len(df)*100:.1f}% entrenamiento, {X_test.shape[0]/len(df)*100:.1f}% prueba")
```

## 7. Creaci√≥n del Pipeline

Creamos un pipeline que incluye:
1. **StandardScaler**: Normaliza los datos (media=0, desviaci√≥n est√°ndar=1)
2. **LinearRegression**: Aplica el modelo de regresi√≥n lineal

```{python}
# Crear el pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),      # Paso 1: Normalizaci√≥n
    ('regressor', LinearRegression())  # Paso 2: Regresi√≥n Lineal
])

print("Pipeline creado con los siguientes pasos:")
for nombre, paso in pipeline.steps:
    print(f"  - {nombre}: {paso.__class__.__name__}")
```

## 8. Entrenamiento del Modelo

Entrenamos el pipeline completo con los datos de entrenamiento.

```{python}
# Entrenar el pipeline
pipeline.fit(X_train, y_train)
print("‚úì Modelo entrenado exitosamente")
```

## 9. Predicciones

Realizamos predicciones con el conjunto de prueba.

```{python}
# Realizar predicciones
y_pred = pipeline.predict(X_test)

# Mostrar las primeras 10 predicciones vs valores reales
comparacion = pd.DataFrame({
    'Valor Real': y_test.values[:10],
    'Predicci√≥n': y_pred[:10],
    'Error': y_test.values[:10] - y_pred[:10]
})
print("Primeras 10 predicciones:")
print(comparacion)
```

## 10. Evaluaci√≥n del Modelo

### 10.1 M√©tricas de desempe√±o

```{python}
# Calcular m√©tricas
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)

# Mostrar resultados
print("="*60)
print("M√âTRICAS DE EVALUACI√ìN DEL MODELO")
print("="*60)
print(f"R¬≤ Score:  {r2:.4f}  ‚Üí Explica el {r2*100:.2f}% de la variabilidad")
print(f"MSE:       {mse:.4f}  ‚Üí Error cuadr√°tico medio")
print(f"RMSE:      {rmse:.4f}  ‚Üí Ra√≠z del error cuadr√°tico medio")
print(f"MAE:       {mae:.4f}  ‚Üí Error absoluto medio")
print("="*60)

# Interpretaci√≥n del R¬≤
if r2 > 0.9:
    print("Interpretaci√≥n: Excelente ajuste del modelo")
elif r2 > 0.7:
    print("Interpretaci√≥n: Buen ajuste del modelo")
elif r2 > 0.5:
    print("Interpretaci√≥n: Ajuste moderado del modelo")
else:
    print("Interpretaci√≥n: Ajuste d√©bil del modelo")
```

### 10.2 Validaci√≥n cruzada

Evaluamos el modelo con validaci√≥n cruzada de 5 particiones.

```{python}
# Validaci√≥n cruzada
cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')

print("\nVALIDACI√ìN CRUZADA (5-fold)")
print("="*60)
print(f"R¬≤ scores por fold: {cv_scores}")
print(f"R¬≤ promedio: {cv_scores.mean():.4f}")
print(f"Desviaci√≥n est√°ndar: {cv_scores.std():.4f}")
print(f"Rango: [{cv_scores.min():.4f}, {cv_scores.max():.4f}]")
```

## 11. Visualizaci√≥n de Resultados

### 11.1 Valores reales vs predicciones

Este gr√°fico muestra qu√© tan cerca est√°n las predicciones de los valores reales.

```{python}
#| fig-width: 10
#| fig-height: 6
#| label: fig-predicciones
#| fig-cap: "Comparaci√≥n entre valores reales y predicciones del modelo"

# Gr√°fico de dispersi√≥n
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6, edgecolors='k', s=80)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'r--', lw=3, label='Predicci√≥n perfecta')
plt.xlabel('Valores Reales', fontsize=13)
plt.ylabel('Predicciones', fontsize=13)
plt.title('Valores Reales vs Predicciones', fontsize=15, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### 11.2 Gr√°fico de residuos

Los residuos son los errores del modelo (diferencia entre valor real y predicci√≥n).

```{python}
#| fig-width: 10
#| fig-height: 6
#| label: fig-residuos
#| fig-cap: "An√°lisis de residuos del modelo"

# Calcular residuos
residuos = y_test - y_pred

# Gr√°fico de residuos
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuos, alpha=0.6, edgecolors='k', s=80)
plt.axhline(y=0, color='r', linestyle='--', lw=3, label='Residuo = 0')
plt.xlabel('Predicciones', fontsize=13)
plt.ylabel('Residuos', fontsize=13)
plt.title('Gr√°fico de Residuos', fontsize=15, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Estad√≠sticas de residuos
print(f"Media de residuos: {residuos.mean():.4f} (idealmente cerca de 0)")
print(f"Desviaci√≥n est√°ndar de residuos: {residuos.std():.4f}")
```

### 11.3 Distribuci√≥n de residuos

```{python}
#| fig-width: 10
#| fig-height: 5
#| label: fig-dist-residuos
#| fig-cap: "Distribuci√≥n de los residuos"

# Histograma de residuos
plt.figure(figsize=(10, 5))
plt.hist(residuos, bins=30, edgecolor='black', alpha=0.7)
plt.axvline(x=0, color='r', linestyle='--', lw=2, label='Residuo = 0')
plt.xlabel('Residuos', fontsize=13)
plt.ylabel('Frecuencia', fontsize=13)
plt.title('Distribuci√≥n de Residuos', fontsize=15, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()
plt.show()
```

## 12. Coeficientes del Modelo

Los coeficientes indican la importancia y direcci√≥n del efecto de cada variable.

### 12.1 Tabla de coeficientes

```{python}
# Extraer el modelo del pipeline
regressor = pipeline.named_steps['regressor']

# Crear DataFrame con coeficientes
coef_df = pd.DataFrame({
    'Variable': X.columns,
    'Coeficiente': regressor.coef_
}).sort_values('Coeficiente', key=abs, ascending=False)

print("COEFICIENTES DEL MODELO")
print("="*60)
print(f"Intercepto: {regressor.intercept_:.4f}\n")
print("Coeficientes por variable (ordenados por magnitud):")
print(coef_df.to_string(index=False))
```

### 12.2 Visualizaci√≥n de coeficientes

```{python}
#| fig-width: 10
#| fig-height: 6
#| label: fig-coeficientes
#| fig-cap: "Importancia de las variables seg√∫n sus coeficientes"

# Gr√°fico de barras horizontales
plt.figure(figsize=(10, 6))
colors = ['green' if x > 0 else 'red' for x in coef_df['Coeficiente']]
plt.barh(coef_df['Variable'], coef_df['Coeficiente'], color=colors, alpha=0.7)
plt.xlabel('Coeficiente', fontsize=13)
plt.ylabel('Variable', fontsize=13)
plt.title('Importancia de las Variables (Coeficientes)', fontsize=15, fontweight='bold')
plt.axvline(x=0, color='black', linestyle='-', linewidth=1)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()
```

### 12.3 Interpretaci√≥n de coeficientes

```{python}
print("\nINTERPRETACI√ìN DE COEFICIENTES:")
print("="*60)
print("Coeficientes positivos ‚Üí Aumentan el valor de la variable objetivo")
print("Coeficientes negativos ‚Üí Disminuyen el valor de la variable objetivo")
print("Mayor magnitud ‚Üí Mayor impacto en la predicci√≥n\n")

# Variables con mayor impacto
print("Top 3 variables con mayor impacto (valor absoluto):")
for idx, row in coef_df.head(3).iterrows():
    direccion = "aumenta" if row['Coeficiente'] > 0 else "disminuye"
    print(f"  {row['Variable']}: {direccion} la predicci√≥n en {abs(row['Coeficiente']):.4f}")
```

## 13. Conclusiones

```{python}
print("RESUMEN DEL AN√ÅLISIS")
print("="*60)
print(f"‚úì Dataset: {df.shape[0]} muestras, {df.shape[1]} variables")
print(f"‚úì Modelo: Regresi√≥n Lineal con Pipeline")
print(f"‚úì R¬≤ Score: {r2:.4f}")
print(f"‚úì RMSE: {rmse:.4f}")
print(f"‚úì Validaci√≥n cruzada (5-fold): {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
print("="*60)
```

## Notas Importantes

- **Variable objetivo**: La variable objetivo es: Rainfall.
- **Preprocesamiento**: El pipeline incluye StandardScaler para normalizar los datos.
- **Interpretaci√≥n**: Los coeficientes est√°n en escala estandarizada debido al StandardScaler.


### **Interpretaci√≥n Final** üß†

* El modelo de regresi√≥n lineal desarrollado permite predecir la precipitaci√≥n acumulada (Rainfall) a partir de variables meteorol√≥gicas medidas en la estaci√≥n. 

* El an√°lisis de los coeficientes revela qu√© variables tienen mayor impacto en la predicci√≥n de la lluvia. Variables como la humedad, la temperatura y la radiaci√≥n solar suelen ser determinantes en los procesos de precipitaci√≥n, lo que se refleja en la magnitud y el signo de sus coeficientes.

* En conclusi√≥n, el modelo es una herramienta √∫til para estimar la precipitaci√≥n a partir de datos meteorol√≥gicos, aunque su precisi√≥n depende de la calidad y representatividad de los datos. Se recomienda complementar este an√°lisis con modelos m√°s complejos o incorporar m√°s datos para mejorar la capacidad predictiva si es necesario.
